{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***ä½¿ç”¨çš„æ¨¡å‹èˆ‡æ–¹æ³•***\n",
        "\n",
        "\n",
        "æ¨¡å‹ï¼šfacebook/blenderbot-400M-distill\n",
        "é€™æ˜¯ä¸€å€‹ç”± Facebook æä¾›çš„ä¸­å°å‹å°è©±æ¨¡å‹ï¼Œèƒ½æ¨¡æ“¬åŸºæœ¬çš„å°è©±å ´æ™¯ã€‚\n",
        "\n",
        "æ–¹æ³•\n",
        "\n",
        "ä½¿ç”¨HuggingFace Transformers å¥—ä»¶è¼‰å…¥BlenderBotæ¨¡å‹å’Œtokenizerã€‚\n",
        "\n",
        "è¨­å®šä¸€æ®µç³»çµ±æç¤ºï¼Œè®“æ©Ÿå™¨äººè§’è‰²å¸¶æœ‰æ‚²è§€æŠ•è³‡è€…çš„èªæ°£ã€‚\n",
        "\n",
        "åˆ©ç”¨Gradioå»ºç«‹ç°¡å–®çš„å°è©±ä»‹é¢ï¼Œè®“ä½¿ç”¨è€…å¯ä»¥åœ¨ç¶²é ä¸Šç›´æ¥èˆ‡æ©Ÿå™¨äººäº’å‹•ã€‚\n",
        "\n",
        "åœ¨ç¨‹å¼ä¸­åŠ ä¸Šmax_lengthå’Œmax_new_tokensçš„åƒæ•¸ï¼Œé¿å…è¶…å‡ºæ¨¡å‹æ”¯æ´çš„æœ€å¤§å­—æ•¸ã€‚"
      ],
      "metadata": {
        "id": "1hIBSqKzlMXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "åŠ å…¥å¥—ä»¶"
      ],
      "metadata": {
        "id": "eHi5E3TxlY6O"
      }
    },
    {
      "source": [
        "# å®‰è£éœ€è¦çš„å¥—ä»¶\n",
        "!pip install transformers gradio\n",
        "\n",
        "# åŒ¯å…¥å¥—ä»¶\n",
        "import gradio as gr\n",
        "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CDwTXJqi9Dz",
        "outputId": "ba56b9fb-4bf3-4bd2-e65e-81dd77db5158"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.29.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.8)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "å»ºç«‹HuggingFace"
      ],
      "metadata": {
        "id": "StLBF9jIjZzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"facebook/blenderbot-400M-distill\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "8Hfig_vvjf87"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pprompt"
      ],
      "metadata": {
        "id": "KIpSRAmLjkEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"ä½ æ˜¯ä¸€ä½ç¶“æ­·å¤šæ¬¡å¸‚å ´å´©ç›¤ã€å°äººæ€§èˆ‡å¸‚å ´éƒ½æ„Ÿåˆ°å¤±æœ›çš„æŠ•è³‡è€…ã€‚è«‹ç”¨å†·éœåˆæ‚²è§€çš„èªæ°£å›ç­”å•é¡Œã€‚\"\n",
        "initial_messages = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt}\n",
        "]\n",
        "\n",
        "def melancholic_investor_chat(user_input, history):\n",
        "    try:\n",
        "        history.append({\"role\": \"user\", \"content\": user_input})\n",
        "        conversation = \" \".join([msg[\"content\"] for msg in history if msg[\"role\"] != \"system\"])\n",
        "        input_text = f\"{system_prompt} {conversation}\"\n",
        "\n",
        "        # Generate response using the model and tokenizer, with max_new_tokens control\n",
        "        inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True)\n",
        "        outputs = model.generate(**inputs, max_new_tokens=100)  # æ§åˆ¶è¼¸å‡ºé•·åº¦\n",
        "        reply = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        history.append({\"role\": \"assistant\", \"content\": reply})\n",
        "\n",
        "        chat_log = []\n",
        "        for i in range(1, len(history), 2):\n",
        "            user_msg = history[i][\"content\"]\n",
        "            bot_msg = history[i + 1][\"content\"] if i + 1 < len(history) else \"\"\n",
        "            chat_log.append((user_msg, bot_msg))\n",
        "\n",
        "        return chat_log, history\n",
        "    except Exception as e:\n",
        "        err_msg = f\"âš ï¸ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}\".encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\")\n",
        "        return [(user_input, err_msg)], history"
      ],
      "metadata": {
        "id": "tkMYohf2jn7K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def melancholic_investor_chat(user_input, history):\n",
        "    try:\n",
        "        history.append({\"role\": \"user\", \"content\": user_input})\n",
        "        conversation = \" \".join([msg[\"content\"] for msg in history if msg[\"role\"] != \"system\"])\n",
        "        input_text = f\"{system_prompt} {conversation}\"\n",
        "\n",
        "        # é™åˆ¶è¼¸å…¥é•·åº¦ï¼Œä¸¦è¨­å®šè¼¸å‡ºå­—æ•¸\n",
        "        inputs = tokenizer(\n",
        "            input_text,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=100  # ç¢ºä¿è¼¸å…¥æœ€å¤šåªä½” 100 tokens\n",
        "        )\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=28  # ç¢ºä¿ç¸½é•·åº¦ â‰¤ 128\n",
        "        )\n",
        "        reply = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        history.append({\"role\": \"assistant\", \"content\": reply})\n",
        "\n",
        "        chat_log = []\n",
        "        for i in range(1, len(history), 2):\n",
        "            user_msg = history[i][\"content\"]\n",
        "            bot_msg = \"\"\n",
        "            if i + 1 < len(history) and history[i + 1][\"role\"] == \"assistant\":\n",
        "                bot_msg = history[i + 1][\"content\"]\n",
        "            chat_log.append((user_msg, bot_msg))\n",
        "\n",
        "        return chat_log, history\n",
        "    except Exception as e:\n",
        "        err_msg = f\"âš ï¸ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}\".encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\")\n",
        "        return [(user_input, err_msg)], history"
      ],
      "metadata": {
        "id": "RChidWJ9kPfF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradioå±•ç¤º"
      ],
      "metadata": {
        "id": "OSIkJFMIjsIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(title=\"æ†‚é¬±çš„è‚¡ç¥¨æŠ•è³‡è€… (Hugging Face)\") as demo:\n",
        "    gr.Markdown(\"## ğŸ’” æ†‚é¬±çš„è‚¡ç¥¨æŠ•è³‡è€… GPT\\nèˆ‡ä¸€ä½ç¶“æ­·å¤šæ¬¡å¸‚å ´å´©ç›¤ã€å°äººæ€§èˆ‡å¸‚å ´éƒ½æ„Ÿåˆ°å¤±æœ›çš„æŠ•è³‡è€æ‰‹èŠå¤©ã€‚\")\n",
        "\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox(label=\"è¼¸å…¥ä½ çš„è¨Šæ¯\")\n",
        "    state = gr.State(initial_messages.copy())\n",
        "\n",
        "    msg.submit(fn=melancholic_investor_chat, inputs=[msg, state], outputs=[chatbot, state])\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "MzVPAJ5cklf7",
        "outputId": "390b1bef-d9c4-4fa9-d9dd-ece1026b2aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-c349d7965adb>:4: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://0d201a31cb2e00c98b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0d201a31cb2e00c98b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}